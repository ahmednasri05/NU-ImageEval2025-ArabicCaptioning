{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T02:43:49.038816Z",
     "iopub.status.busy": "2025-08-18T02:43:49.038425Z",
     "iopub.status.idle": "2025-08-18T02:43:49.044794Z",
     "shell.execute_reply": "2025-08-18T02:43:49.043616Z",
     "shell.execute_reply.started": "2025-08-18T02:43:49.038779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -U google-generativeai\n",
    "!pip install genai\n",
    "!pip install -U langchain-community\n",
    "!pip install faiss-cpu\n",
    "!pip install camel-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T01:33:56.532457Z",
     "iopub.status.busy": "2025-08-18T01:33:56.532134Z",
     "iopub.status.idle": "2025-08-18T01:33:56.567630Z",
     "shell.execute_reply": "2025-08-18T01:33:56.566267Z",
     "shell.execute_reply.started": "2025-08-18T01:33:56.532433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import camel_tools \n",
    "from camel_tools.utils.normalize import normalize_unicode\n",
    "from camel_tools.utils.normalize import normalize_alef_maksura_ar\n",
    "from camel_tools.utils.normalize import normalize_alef_ar\n",
    "from camel_tools.utils.normalize import normalize_teh_marbuta_ar\n",
    "from camel_tools.utils.dediac import dediac_ar\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "from camel_tools.disambig.mle import MLEDisambiguator\n",
    "import re\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "import google.generativeai as genai\n",
    "from tqdm.auto import tqdm\n",
    "import os, time\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-14T06:21:19.358169Z",
     "iopub.status.idle": "2025-08-14T06:21:19.358538Z",
     "shell.execute_reply": "2025-08-14T06:21:19.358362Z",
     "shell.execute_reply.started": "2025-08-14T06:21:19.358347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    for i in range(len(df)):\n",
    "        sentence = df.loc[i , 'arabic_caption']\n",
    "        sentence = normalize_unicode(sentence)\n",
    "        sentence = dediac_ar(sentence)\n",
    "        sentence = normalize_alef_maksura_ar(sentence)\n",
    "        sentence = normalize_alef_ar(sentence)\n",
    "        df.loc[i , 'arabic_caption'] = sentence\n",
    "        #sentence = normalize_teh_marbura_ar\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T02:44:04.921684Z",
     "iopub.status.busy": "2025-08-18T02:44:04.921309Z",
     "iopub.status.idle": "2025-08-18T02:45:18.318400Z",
     "shell.execute_reply": "2025-08-18T02:45:18.316922Z",
     "shell.execute_reply.started": "2025-08-18T02:44:04.921657Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36/450441757.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=model_name)\n",
      "2025-08-18 02:44:30.693120: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755485071.019286      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755485071.105541      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc26dcf9e2a43909c30011850cee0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b289d943f2f4ee2a25585dce65d9462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b49838217ae4bc0a74e8b90bb9947ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c1ef4fad5d4b3199177141344ad0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc21c1f950d74480aae2f0ca102e8553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b9ae2d64cf4ed0af8d6dadbde0efde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686c58688d1c48fe8026c34142d05e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315a16b4ecd74012a439da4c25e107c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b022a17db4ca42859ce64674e90cda3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de536cd0a1524f59899afbbe2c9f839e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-14T06:21:19.375590Z",
     "iopub.status.idle": "2025-08-14T06:21:19.376143Z",
     "shell.execute_reply": "2025-08-14T06:21:19.375923Z",
     "shell.execute_reply.started": "2025-08-14T06:21:19.375904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "truth = pd.read_csv(\"/kaggle/input/dataset/Augmented_data.csv\")\n",
    "texts = truth['Description'].to_list() \n",
    "metadatas = [{\"caption_index\": i} for i in range(len(texts))]\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "vectorstore = FAISS.from_texts(texts, embedding_model, metadatas=metadatas)\n",
    "vectorstore.save_local(\"new_faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T02:46:42.366221Z",
     "iopub.status.busy": "2025-08-18T02:46:42.365644Z",
     "iopub.status.idle": "2025-08-18T02:46:43.008491Z",
     "shell.execute_reply": "2025-08-18T02:46:43.007152Z",
     "shell.execute_reply.started": "2025-08-18T02:46:42.366176Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "Content: تواصل هدم حاره المغاربه طريق النبي داود التي نزعت ملكيتها من اهلها وهدمت كجزء من تغيير مشهد البلده القديمه الذي قامت به قوات الاستعمار الصهيوني بعد حرب مجهوله التاريخ والمصور\n",
      "Caption Index: 333\n",
      "Result 2:\n",
      "Content: تواصل هدم حاره المغاربه طريق النبي داود التي نزعت ملكيتها من اهلها وهدمت كجزء من تغيير مشهد البلده القديمه الذي قامت به قوات الاستعمار الصهيوني بعد حرب مجهوله التاريخ والمصور\n",
      "Caption Index: 366\n",
      "Result 3:\n",
      "Content: اثار نسف دار و كوع في البلده القديمه في القدس ووفقا للتعقيب المرفق للصوره شمل النسف الدرج وجزء من العماره\n",
      "Caption Index: 345\n"
     ]
    }
   ],
   "source": [
    "loaded_vectorstore = FAISS.load_local(\"/kaggle/input/new-fiass\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/dataset/captions_finetuned_cleaned.csv\" , encoding = 'utf-8-sig')\n",
    "query = df.loc[0 , \"caption\"]  \n",
    "results = loaded_vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Result {i+1}:\")\n",
    "    print(f\"Content: {result.page_content}\")\n",
    "    print(f\"Caption Index: {result.metadata['caption_index']}\")\n",
    "    #print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T02:48:13.633785Z",
     "iopub.status.busy": "2025-08-18T02:48:13.631857Z",
     "iopub.status.idle": "2025-08-18T02:48:15.172787Z",
     "shell.execute_reply": "2025-08-18T02:48:15.171390Z",
     "shell.execute_reply.started": "2025-08-18T02:48:13.633730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "os.environ['GEMINI_API_KEY'] = \"Your_Api_Key\"\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T02:47:42.766075Z",
     "iopub.status.busy": "2025-08-18T02:47:42.765659Z",
     "iopub.status.idle": "2025-08-18T02:47:42.775756Z",
     "shell.execute_reply": "2025-08-18T02:47:42.773970Z",
     "shell.execute_reply.started": "2025-08-18T02:47:42.766047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def RAG_Generated_caption(caption):\n",
    "    query = caption\n",
    "    retrieved_docs = loaded_vectorstore.similarity_search(query, k=5)\n",
    "\n",
    "    retrieved_text = \"\"\n",
    "    for i, result in enumerate(retrieved_docs):\n",
    "        retrieved_text += f\"- {result.page_content.strip()}\\n\"\n",
    "\n",
    "    \n",
    "    prompt = (\n",
    "        \"You are given an image caption generated by a model and a set of retrieved captions from a specialized dataset.\\n\"\n",
    "        \"Your task is to refine the generated caption to match the tone, style, and domain-specific language of the retrieved captions.\\n\"\n",
    "        \"Ensure historical accuracy and preserve the semantic meaning of the original caption.\\n\"\n",
    "        \"Match the tone, vocabulary, and structure used in the retrieved captions.\\n\"\n",
    "        \"Do not hallucinate facts. Focus on enhancing the alignment of the generated caption with the retrieved examples.\\n\\n\"\n",
    "        \"Retrieved captions:\\n\"\n",
    "        f\"{retrieved_text}\\n\"\n",
    "        \"Original caption:\\n\"\n",
    "        f\"{query}\\n\\n\"\n",
    "        \"Adapted caption:\"\n",
    "    )\n",
    "\n",
    "    response = genai.GenerativeModel(\"gemini-2.5-flash\").generate_content(prompt)\n",
    "    reply = response.candidates[0].content.parts[0].text\n",
    "\n",
    "    return reply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T02:46:51.237356Z",
     "iopub.status.busy": "2025-08-18T02:46:51.236714Z",
     "iopub.status.idle": "2025-08-18T02:46:51.246900Z",
     "shell.execute_reply": "2025-08-18T02:46:51.244385Z",
     "shell.execute_reply.started": "2025-08-18T02:46:51.237313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokens = [\n",
    "#all gemini tokens    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-14T06:21:19.390055Z",
     "iopub.status.idle": "2025-08-14T06:21:19.390440Z",
     "shell.execute_reply": "2025-08-14T06:21:19.390259Z",
     "shell.execute_reply.started": "2025-08-14T06:21:19.390242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "for i, token in enumerate(tokens):\n",
    "    try:\n",
    "        os.environ['GEMINI_API_KEY'] = token\n",
    "        genai.configure(api_key=token)\n",
    "        model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "        response = model.generate_content(\"Hello, are you active?\")\n",
    "        print(f\"Token {i} is VALID. Response: {response.text[:30]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Token {i} is INVALID. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T00:54:07.040722Z",
     "iopub.status.busy": "2025-08-09T00:54:07.040433Z",
     "iopub.status.idle": "2025-08-09T00:54:43.397744Z",
     "shell.execute_reply": "2025-08-09T00:54:43.396329Z",
     "shell.execute_reply.started": "2025-08-09T00:54:07.040702Z"
    }
   },
   "source": [
    "#perhaps 465 and 466 were skipped, don't forget them \n",
    "#new_generated = []\n",
    "#new_index = len(new_generated)\n",
    "#1390 was skipped -> do it\n",
    "j = 0\n",
    "for i in range(1634, len(df)):\n",
    "    try:\n",
    "        new_cap = RAG_Generated_caption(df.loc[i, \"arabic_caption\"])\n",
    "        file_name = df.loc[i, 'File Name']\n",
    "        new_generated.append((file_name, new_cap))\n",
    "        if i % 50 == 0:\n",
    "            print(i)\n",
    "        if (i - 465) % 200 == 0 and j < len(tokens): \n",
    "            os.environ['GEMINI_API_KEY'] = tokens[j]\n",
    "            genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "            print(\"API token rotated BING BING\")\n",
    "            print(i)\n",
    "            j += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping index {i} due to error: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-14T06:21:19.408211Z",
     "iopub.status.idle": "2025-08-14T06:21:19.408508Z",
     "shell.execute_reply": "2025-08-14T06:21:19.408359Z",
     "shell.execute_reply.started": "2025-08-14T06:21:19.408345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/dataset/captions_finetuned_cleaned_test.csv\" , encoding = \"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T02:48:19.310064Z",
     "iopub.status.busy": "2025-08-18T02:48:19.309660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating captions:   1%|          | 4/752 [01:05<3:27:42, 16.66s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quota exceeded for token 0, rotating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating captions:  15%|█▍        | 110/752 [28:27<2:44:50, 15.41s/file]"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/dataset/captions_finetuned_cleaned_old.csv\" , encoding = \"utf-8-sig\")\n",
    "j = 0\n",
    "useless = 0\n",
    "gen = []\n",
    "\n",
    "for i in tqdm(range(len(df)), desc=\"Generating captions\", unit=\"file\"):\n",
    "    file_name = df.loc[i, 'image_id']\n",
    "    caption = df.loc[i, \"caption\"]\n",
    "\n",
    "    while True:  \n",
    "        try:\n",
    "            new_cap = RAG_Generated_caption(caption)\n",
    "            gen.append((file_name, new_cap))\n",
    "            break  \n",
    "\n",
    "        except Exception as e:\n",
    "            err_str = str(e).lower()\n",
    "\n",
    "            if \"quota\" in err_str or \"429\" in err_str:\n",
    "                print(f\"Quota exceeded for token {j}, rotating...\")\n",
    "                j += 1\n",
    "                if j >= len(tokens):\n",
    "                    new_df = pd.DataFrame(gen, columns=[\"image_id\", \"caption\"])\n",
    "                    new_df.to_csv(\"/kaggle/working/captions_rag_test_clean.csv\", encoding=\"utf-8-sig\", index=False)\n",
    "                    while True:\n",
    "                        print(f\"Still alive at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "                        time.sleep(14400)\n",
    "                os.environ['GEMINI_API_KEY'] = tokens[j]\n",
    "                genai.configure(api_key=tokens[j])\n",
    "                time.sleep(2)  \n",
    "\n",
    "            else:\n",
    "                print(f\"Unexpected error at index {i}: {e}. Retrying...\")\n",
    "                time.sleep(2)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T06:40:28.271235Z",
     "iopub.status.busy": "2025-08-14T06:40:28.270578Z",
     "iopub.status.idle": "2025-08-14T06:40:28.288222Z",
     "shell.execute_reply": "2025-08-14T06:40:28.287128Z",
     "shell.execute_reply.started": "2025-08-14T06:40:28.271208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(generated , columns = [\"File Name\" , \"arabic_caption\"])\n",
    "new_df.to_csv(\"/kaggle/working/captions_rag_test_full.csv\",encoding = \"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-14T06:21:19.448212Z",
     "iopub.status.idle": "2025-08-14T06:21:19.448546Z",
     "shell.execute_reply": "2025-08-14T06:21:19.448417Z",
     "shell.execute_reply.started": "2025-08-14T06:21:19.448401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r /kaggle/working/new_faiss_index.zip /kaggle/working/new_faiss_index"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8029100,
     "sourceId": 12704173,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8029339,
     "sourceId": 12704502,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8029364,
     "sourceId": 12704534,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8029635,
     "sourceId": 12704944,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8029866,
     "sourceId": 12705330,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8029869,
     "sourceId": 12705336,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8029913,
     "sourceId": 12705405,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8033167,
     "sourceId": 12710219,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8035310,
     "sourceId": 12713321,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8035404,
     "sourceId": 12713464,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8038337,
     "sourceId": 12717979,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8039199,
     "sourceId": 12719202,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8043194,
     "sourceId": 12725287,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8045632,
     "sourceId": 12729038,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8052087,
     "sourceId": 12738319,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8059185,
     "sourceId": 12749103,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8065669,
     "sourceId": 12759112,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8066854,
     "sourceId": 12760955,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8087689,
     "sourceId": 12792140,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8087792,
     "sourceId": 12792339,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
